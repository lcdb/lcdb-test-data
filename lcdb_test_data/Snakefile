import gzip
import os
from Bio import SeqIO
from Bio.Seq import Seq
from textwrap import dedent

# required to avoid near-simultaneous timestamps that confuse snakemake
shell.prefix('sleep 2;')

n = range(1, 5)
rule all:
    input:
        expand(
            'samples/sample{n}/sample{n}.{prefix}.{paired}.bam',
            n=n, paired=['paired', 'single'], prefix=['full']
        ) + [
            #'annotation/dm6.small.refflat',
            'seq/dm6.small.transcriptome.fa',
            'LIMIT.bed',
        ]
        #+ expand('samples/sample{n}/sample{n}_R{N}.fastq.gz', n=n, N=[1, 2])
        + expand('samples/sample{n}/sample{n}.small_R{N}.fastq.gz', n=n, N=[1,2])


# ----------------------------------------------------------------------------
# Create a BED file that will be used to subset GTF and FASTA files
rule limits:
    output: 'LIMIT.bed'
    shell:
        'echo "2L	0	1000000	2L" > {output}; '
        'echo "2R	0	1000000	2R" >> {output}'


# ----------------------------------------------------------------------------
# Download FlyBase GTF
rule prep_gtf:
    output: 'annotation/dm6.full.gtf'
    shell:
        'wget --no-clobber -q '
        '-O- '
        'ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r6.11_FB2016_03/gtf/dmel-all-r6.11.gtf.gz > tmp.gtf.gz '
        '&& zcat tmp.gtf.gz | bedtools sort -i stdin | grep exon > {output} '
        '&& rm tmp.gtf.gz '


# ----------------------------------------------------------------------------
# Subset GTF based on limits
rule prep_small_gtf:
    input:
        gtf=rules.prep_gtf.output,
        limit=rules.limits.output
    output: 'annotation/dm6.small.gtf'
    shell:
        'bedtools intersect -a {input.gtf} -b {input.limit} > {output} '


# ----------------------------------------------------------------------------
# Download Flybase transcriptome FASTA
rule prep_transcriptome:
    input: rules.prep_gtf.output
    output: 'seq/dm6.full.transcriptome.fa'
    shell:
        'wget --no-clobber -q '
        '-O- '
        'ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r6.11_FB2016_03/fasta/dmel-all-transcript-r6.11.fasta.gz '
        '| gzip -d -c > {output} '

# ----------------------------------------------------------------------------
# Subset transcriptome based on transcript IDs retained in the subsetted GTF
rule prep_small_transcriptome:
    input:
        gtf=rules.prep_small_gtf.output,
        fasta=rules.prep_transcriptome.output
    output: 'seq/dm6.small.transcriptome.fa'
    run:
        from Bio import SeqIO
        import gffutils
        features = gffutils.iterators.DataIterator(str(input.gtf))
        keep = set([i.attributes['transcript_id'][0] for i in features])
        parser = SeqIO.parse(str(input.fasta), 'fasta')
        recs = []
        for rec in parser:
            if rec.name in keep:
                recs.append(rec)
        with open(output[0], 'w') as fout:
            SeqIO.write(recs, fout, 'fasta')

# ----------------------------------------------------------------------------
# Convert small GTF to refflat
rule gtftorefflat:
    input: rules.prep_small_gtf.output
    output: 'annotation/dm6.small.refflat'
    shell:
        'gtfToGenePred {input} {output}.tmp '
        '&& paste <(cut -f1 {output}.tmp) {output}.tmp > {output} '
        '&& rm {output}.tmp'


# ----------------------------------------------------------------------------
# Download full fasta
rule prep_fasta:
    input: rules.limits.output
    output: 'seq/dm6.full.fa'
    shell:
        'wget --no-clobber -q '
        '-O- ftp://ftp.flybase.net/genomes/Drosophila_melanogaster/dmel_r6.11_FB2016_03/fasta/dmel-all-chromosome-r6.11.fasta.gz '
        '| gunzip -c > {output} '

# ----------------------------------------------------------------------------
# Subset genome fasta
rule prep_small_fasta:
    input:
        fasta=rules.prep_fasta.output,
        limits=rules.limits.output
    output: 'seq/dm6.small.fa'
    shell:
        'bedtools getfasta -fi {input.fasta} -bed {input.limits} -fo {output} -name '


rule download_fastqs:
    output:
        fastq_R1='samples/{sample}/{sample}.full_R1.fastq.gz',
        fastq_R2='samples/{sample}/{sample}.full_R2.fastq.gz'
    run:
        accession = {
            'sample1': 'SRR948304',
            'sample2': 'SRR948305',
            'sample3': 'SRR948306',
            'sample4': 'SRR948307',
        }[wildcards.sample]
        shell('fastq-dump {accession} --split-files')
        shell('gzip -c {accession}_1.fastq > {output.fastq_R1}')
        shell('gzip -c {accession}_2.fastq > {output.fastq_R2}')



# ----------------------------------------------------------------------------
# HISAT2 index
rule hisat_index:
    input: rules.prep_fasta.output
    output: expand('seq/dm6.full.{n}.ht2', n=range(1,8))
    params: index='seq/dm6.full'
    log: 'seq/dm6.small.ht2.log'
    shell:
        'hisat2-build {input} {params.index} &> {log}'


# ----------------------------------------------------------------------------
# HISAT2 align.
#
# Note we're creating both SE and PE bams in serial rather than parallel
# (simplifies the snakefile)
rule hisat_align:
    input:
        index=expand('seq/dm6.full.{n}.ht2', n=range(1,8)),
        fastq_R1=rules.download_fastqs.output.fastq_R1,
        fastq_R2=rules.download_fastqs.output.fastq_R2,
    output:
        paired=temporary('samples/{sample}/{sample}.full.paired.sam'),
        single=temporary('samples/{sample}/{sample}.full.single.sam'),
    params: index='seq/dm6.full'
    threads: 8
    run:
        shell(
            'hisat2 '
            '-x {params.index} '
            '-1 {input.fastq_R1} '
            '-2 {input.fastq_R2} '
            '-S {output.paired}'
        )
        shell(
            'hisat2 '
            '-x {params.index} '
            '-U {input.fastq_R1} '
            '-S {output.single}'
        )

# ------------------------------------------------------------------------------
# HISAT2 outputs SAM but most tools use BAM
rule bam:
    input:
        paired=rules.hisat_align.output.paired,
        single=rules.hisat_align.output.single
    output:
        paired='samples/{sample}/{sample}.full.paired.bam',
        single='samples/{sample}/{sample}.full.single.bam'
    run:
        shell('samtools view -Sb {input.paired} > {output.paired}')
        shell('samtools view -Sb {input.single} > {output.single}')

rule sortbam:
    input:
        paired=rules.bam.output.paired,
        single=rules.bam.output.single,
    output:
        paired='samples/{sample}/{sample}.full.paired.sorted.bam',
        single='samples/{sample}/{sample}.full.single.sorted.bam'
    shell:
        'samtools sort -m 4G {input.paired} > {output.paired} '
        '&& samtools sort {input.single} > {output.single} '


# Previous iterations tried to subset the BAM by the limits and then convert to
# FASTQ. But since mates can span the limit boundaries, this can result in
# FASTQs with mismatched read counts.
#
# Still other iterations had tried to map to a restricted reference, but this
# still took a while, and any changes that would need to be made (e.g. in
# number of reads, or in the limits) would trigger a re-run from the beginning,
# including building the reference.
#
# Using seqtk here ensures that we're working at the read name level which,
# after all is what we care about for making a small FASTQ.
#
# Also note the parameters here for the maximum number of mapped and unmapped
# reads to include in the final small FASTQ.
rule small_fastq:
    input:
        bam=rules.sortbam.output.paired,
        full_fastq_R1=rules.download_fastqs.output.fastq_R1,
        full_fastq_R2=rules.download_fastqs.output.fastq_R2,
        limits=rules.limits.output
    output:
        mapped_names='samples/{sample}/{sample}.small.names.mapped.lst',
        unmapped_names='samples/{sample}/{sample}.small.names.unmapped.lst',
        R1='samples/{sample}/{sample}.small_R1.fastq',
        R2='samples/{sample}/{sample}.small_R2.fastq'
    params:
        mapped_n=3000000,
        unmapped_n=1000
    shell:
        'samtools view -h -L {input.limits} {input.bam} '
        '| samtools view -f 3 - | cut -f1 | uniq | head -n {params.mapped_n} > {output.mapped_names} '
        '&& samtools view -f 4 {input.bam} | cut -f1 | uniq | head -n {params.unmapped_n} > {output.unmapped_names} '
        '&& seqtk subseq {input.full_fastq_R1} {output.mapped_names} > {output.R1} '
        '&& seqtk subseq {input.full_fastq_R1} {output.unmapped_names} >> {output.R1} '
        '&& seqtk subseq {input.full_fastq_R2} {output.mapped_names} > {output.R2} '
        '&& seqtk subseq {input.full_fastq_R2} {output.unmapped_names} >> {output.R2} '


rule gzipped_fastq:
    input:
        'samples/{sample}/{sample}{prefix}.fastq'
    output:
        'samples/{sample}/{sample}{prefix}.fastq.gz'
    shell:
        'gzip {input}'



# vim: ft=python
